# ğŸŒ Multilingual Retrieval System (Ollama + Chroma + Streamlit)

This project is a **multilingual semantic search system** built using:

* **Ollama** for local embedding generation
* **Chroma** for vector storage
* **Streamlit** for an interactive UI

You can upload a multilingual dataset, build a vector store, and query in **any language**.
The system will show both:

* the **original text**, and
* the **English translation** (from the dataset column `en_translation`)

The repo also includes a sample dataset: **`multilingual_dataset.csv`**.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ retrival_system.py        # Core retrieval and embedding logic
â”œâ”€â”€ streamlit_app.py          # Streamlit frontend
â”œâ”€â”€ multilingual_dataset.csv  # Sample dataset for testing
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md
```

---

## ğŸ§  Requirements

* Python 3.9â€“3.11
* Ollama installed locally
* Works on macOS, Linux, and Windows (via WSL)

---

## âš™ï¸ Installing Ollama

1. Download & install from:
   **[https://ollama.com](https://ollama.com)**

2. Pull the embedding model used in this project:

```bash
ollama pull snowflake-arctic-embed2
```

3. Verify Ollama is running:

```bash
curl http://localhost:11434/api/tags
```

You should see a JSON response listing available models.

If Ollama isnâ€™t running:

* **macOS:** Open the Ollama app
* **Linux/WSL:**

```bash
ollama serve
```

---

## ğŸ“¦ Install Python Dependencies

### Create a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate      # macOS/Linux
# .venv\Scripts\activate       # Windows
```

### Install required packages

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Running the Streamlit App

From the project root:

```bash
streamlit run streamlit_app.py
```

This will open the interface at:

```
http://localhost:8501
```

---

## ğŸ§ª Using the App

### 1. Upload Dataset

Use **multilingual_dataset.csv** or your own dataset containing:

* `doc_id`
* `lang`
* `text`
* `en_translation`

### 2. Build Vector Store

Click **"ğŸ”„ Build / Rebuild Vector Store"**.
The system will embed all documents using `snowflake-arctic-embed2` and store them in Chroma.

### 3. Search

Enter any query in any language.
The app will show:

* Rank
* Similarity score
* Original text preview
* English translation preview
* Full text + translation for the top result

---

## â— Troubleshooting

### âŒ Error: â€œModel not foundâ€

Run:

```bash
ollama pull snowflake-arctic-embed2
```

### âŒ Error: Cannot connect to Ollama

Start the Ollama server:

```bash
ollama serve
```

### âŒ Missing CSV columns

Ensure the dataset includes:

```
doc_id, lang, text, en_translation
```